{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import koreanize_matplotlib"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data import 및 확인"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"five_minute/한국전력거래소_5분단위 전력수급현황_20230430.csv\", encoding='cp949', index_col='기준일시', parse_dates=True)\n",
    "df\n",
    "# 종속변수는 현재수요(MW)로 설정한다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[['현재수요(MW)']].plot(figsize =(20,10));"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from statsmodels.tsa.statespace.tools import diff\n",
    "diff(df[\"현재수요(MW)\"], k_diff=1).plot(figsize=(12,8));"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Target data 추출"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## train 데이터 추출"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# train기간\n",
    "train = df.loc[:'2023-03-12 23:55:00']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train.to_csv(\"train.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train = train.drop(\"현재수요(MW)\", axis=1)\n",
    "X_train.to_csv(\"X_train.csv\")\n",
    "y_train = train['현재수요(MW)']\n",
    "y_train.to_csv(\"y_train.csv\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## test 데이터 추출"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# test기간\n",
    "test = df.loc['2023-03-13 00:00:00':'2023-03-19 23:55:00']\n",
    "test.to_csv(\"test.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_test = test.drop(\"현재수요(MW)\", axis=1)\n",
    "X_test.to_csv(\"X_test.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y = test['현재수요(MW)']\n",
    "y.to_csv(\"y.csv\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_test.shape, y.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## train, test 분포 비교"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train.plot(figsize = (12,8));"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test.plot(figsize = (12,8));"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Ensemble"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## RandomForest(GridSearch)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 기상데이터 import\n",
    "df_final = pd.read_csv(\"meteorological/df_final.csv\", index_col=0, parse_dates=True) # 기상데이터 total 최종본\n",
    "df_final.index.freq = '5T'\n",
    "train = pd.read_csv(\"meteorological/train.csv\", index_col=0, parse_dates=True) # 2022-04-01 00:00:00 ~ 2023-03-12 23:55:00 까지의 데이터\n",
    "train.index.freq = '5T'\n",
    "X_train = pd.read_csv(\"meteorological/X_train.csv\", index_col=0, parse_dates=True)\n",
    "X_train.index.freq='5T'\n",
    "y_train = pd.read_csv(\"meteorological/y_train.csv\", index_col=0, parse_dates=True)\n",
    "y_train.index.freq='5T'\n",
    "test = pd.read_csv(\"meteorological/test.csv\", index_col=0, parse_dates=True) # 2023-03-13 00:00:00':'2023-03-19 23:55:00' 까지의 데이터\n",
    "test.index.freq = '5T'\n",
    "X_test = pd.read_csv(\"meteorological/X_test.csv\", index_col=0, parse_dates=True)\n",
    "X_test.index.freq = '5T'\n",
    "y = pd.read_csv(\"meteorological/y.csv\", index_col=0, parse_dates=True)\n",
    "y.index.freq = '5T'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_percentage_error as mape\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_score_splited_train(model, xtrain, xtest, ytrain, ytest):\n",
    "    A = model.score(xtrain, ytrain)\n",
    "    B = model.score(xtest,ytest)\n",
    "    pred = model.predict(xtest)\n",
    "    C = mape(ytest, pred)\n",
    "\n",
    "    print(f\"ACC train : {A:.4f}, test : {B:.4f}, mape : {C:.4f}\" )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 랜덤 포레스트 회귀 모델을 준비합니다.\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# 탐색할 하이퍼파라미터의 범위를 지정합니다.\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],    # 트리의 개수\n",
    "    'max_depth': [None, 10, 20, 30],   # 트리의 최대 깊이\n",
    "    'min_samples_split': [2, 5, 10],   # 노드를 분할하기 위한 최소한의 샘플 데이터 수\n",
    "    'min_samples_leaf': [1, 2, 4],     # 리프 노드가 되기 위한 최소한의 샘플 데이터 수\n",
    "    'bootstrap': [True, False]         # 부트스트랩(중복 허용 샘플링) 사용 여부\n",
    "}\n",
    "\n",
    "# 그리드 탐색을 준비합니다.\n",
    "# cv는 cross-validation의 fold 수를 나타냅니다.\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, verbose=2, n_jobs=-1)\n",
    "\n",
    "# 데이터 X와 타겟 y에 대해 그리드 탐색을 수행합니다.\n",
    "grid_search.fit(xtrain, ytrain)\n",
    "\n",
    "# 최적의 하이퍼파라미터를 출력합니다.\n",
    "print(grid_search.best_params_)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_rf = RandomForestRegressor(random_state=42, bootstrap=True, max_depth=None, min_samples_leaf= 1, min_samples_split=2, n_estimators=200)\n",
    "best_rf.fit(xtrain,ytrain)\n",
    "get_score_splited_train(best_rf, xtrain, xtest, ytrain, ytest)\n",
    "prediction = best_rf.predict(X_test)\n",
    "mape(y, prediction)\n",
    "feature_importances = pd.DataFrame(best_rf.feature_importances_,\n",
    "                                   index = xtrain.columns,\n",
    "                                   columns=['importance']).sort_values('importance', ascending=False)\n",
    "print(feature_importances)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "prediction = pd.Series(prediction)\n",
    "prediction.index = y.index\n",
    "prediction"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(prediction, label = 'rf')\n",
    "plt.plot(y, label = 'y')\n",
    "plt.xlabel(y.index)\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 모든 데이터 학습\n",
    "best_rf.fit(X_train,y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "prediction = best_rf.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(mape(y, prediction))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "feature_importances = pd.DataFrame(best_rf.feature_importances_,\n",
    "                                   index = xtrain.columns,\n",
    "                                   columns=['importance']).sort_values('importance', ascending=False)\n",
    "print(feature_importances)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "prediction = pd.Series(prediction)\n",
    "prediction.index = y.index\n",
    "prediction"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(prediction, label = 'rf')\n",
    "plt.plot(y, label = 'y')\n",
    "# plt.xlabel(y.index)\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Time Series 변수 생성"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "# pt = PowerTransformer(method='yeo-johnson')\n",
    "# df['column'] = pt.fit_transform(df[['column']])\n",
    "\n",
    "scaler= MinMaxScaler()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Time Series 분석에 따른 target time 변수\n",
    "target_time = [25,68,156,288,576]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "target_list = list(X_train.columns)\n",
    "target_list"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "TES_X_train = X_train.copy()\n",
    "TES_X_test = X_test.copy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 0 값의 오류로 인한 로그변환\n",
    "for col in target_list:\n",
    "    TES_X_train[col] = scaler.fit_transform(TES_X_train[[col]])\n",
    "    TES_X_test[col] = scaler.fit_transform(TES_X_test[[col]])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "TES_X_train.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from tqdm import tqdm\n",
    "def make_TES_se_add(target_time, col, TES_X_train, TES_X_test):\n",
    "    for i in tqdm(target_time):\n",
    "        model_add = ExponentialSmoothing(TES_X_train[col], trend='add', seasonal='add', seasonal_periods=i).fit()\n",
    "        TES_X_train[f'TESadd_add{i}{col}'] = model_add.fittedvalues\n",
    "        model_add = ExponentialSmoothing(TES_X_test[col], trend='add', seasonal='add', seasonal_periods=i).fit()\n",
    "        TES_X_test[f'TESadd_add{i}{col}'] = model_add.fittedvalues\n",
    "\n",
    "#\n",
    "#     for i in tqdm(target_time):\n",
    "#         model_add = ExponentialSmoothing(TES_X_train[col], trend='mul', seasonal='add', seasonal_periods=i).fit()\n",
    "#         TES_X_train[f'TESmul_add{i}{col}'] = model_add.fittedvalues\n",
    "#         model_add = ExponentialSmoothing(TES_X_test[col], trend='mul', seasonal='add', seasonal_periods=i).fit()\n",
    "#         TES_X_test[f'TESmul_add{i}{col}'] = model_add.fittedvalues\n",
    "    return TES_X_train, TES_X_test\n",
    "#\n",
    "# # TES_X_train.tail()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def make_TES_mul(target_time, col, TES_X_train, TES_X_test):\n",
    "    for i in tqdm(target_time):\n",
    "        model_add = ExponentialSmoothing(TES_X_train[col], trend='mul', seasonal='add', seasonal_periods=i).fit()\n",
    "        TES_X_train[f'TESmul_add{i}{col}'] = model_add.fittedvalues\n",
    "        model_add = ExponentialSmoothing(TES_X_test[col], trend='mul', seasonal='add', seasonal_periods=i).fit()\n",
    "        TES_X_test[f'TESmul_add{i}{col}'] = model_add.fittedvalues\n",
    "\n",
    "\n",
    "    for i in tqdm(target_time):\n",
    "        model_mul = ExponentialSmoothing(TES_X_train[col], trend='mul', seasonal='mul', seasonal_periods=i).fit()\n",
    "        TES_X_train[f'TESmul_mul{i}{col}'] = model_mul.fittedvalues\n",
    "        model_mul = ExponentialSmoothing(TES_X_test[col], trend='mul', seasonal='mul', seasonal_periods=i).fit()\n",
    "        TES_X_test[f'TESmul_mul{i}{col}'] = model_mul.fittedvalues\n",
    "    return TES_X_train, TES_X_test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for col in target_list:\n",
    "    TES_X_train, TES_X_test = make_TES_se_add(target_time, col, TES_X_train, TES_X_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "TES_X_train.tail()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "TES_X_test.tail()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 모든 데이터 학습\n",
    "import pickle\n",
    "def run_model(TES_X_train, TES_X_test, y_train, y):\n",
    "    best_rf = RandomForestRegressor(random_state=42, bootstrap=True, max_depth=None, min_samples_leaf= 1, min_samples_split=2, n_estimators=200)\n",
    "    best_rf.fit(TES_X_train,y_train)\n",
    "    prediction = best_rf.predict(TES_X_test)\n",
    "    print(f\"mape : {mape(y, prediction):.4f}\")\n",
    "    feature_importances = pd.DataFrame(best_rf.feature_importances_,\n",
    "                                       index = TES_X_test.columns,\n",
    "                                       columns=['importance']).sort_values('importance', ascending=False)\n",
    "    print(feature_importances)\n",
    "\n",
    "    prediction = pd.Series(prediction)\n",
    "    prediction.index = y.index\n",
    "    prediction\n",
    "    plt.figure(figsize=(12,8))\n",
    "    plt.plot(prediction, label = 'rf')\n",
    "    plt.plot(y, label = 'y')\n",
    "    plt.xlabel(y.index)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    with open('meteorological/model/rf/all_feature_rf_model.pkl', 'wb') as file:\n",
    "        pickle.dump(best_rf, file)\n",
    "    return"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "run_model(TES_X_train, TES_X_test,y_train, y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "feature_importances"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 단계선택법"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 단계선택법\n",
    "\n",
    "\n",
    "\n",
    "def rfecv_run_model(TES_X_train, TES_X_test, y_train, y):\n",
    "    best_rf = RandomForestRegressor(random_state=42, bootstrap=True, max_depth=None, min_samples_leaf=1,\n",
    "                                    min_samples_split=2, n_estimators=200)\n",
    "    rfecv = RFECV(estimator=best_rf)\n",
    "\n",
    "    rfecv.fit(TES_X_train, np.ravel(y_train))\n",
    "    prediction = rfecv.predict(TES_X_test)\n",
    "    print(f\"mape : {mape(y, prediction):.4f}\")\n",
    "    # feature_importances = pd.DataFrame(rfecv.feature_,\n",
    "    #                                    index=TES_X_test.columns,\n",
    "    #                                    columns=['importance']).sort_values('importance', ascending=False)\n",
    "    # print(feature_importances)\n",
    "\n",
    "    # prediction = pd.Series(prediction)\n",
    "    # prediction.index = y.index\n",
    "    # prediction\n",
    "    # plt.figure(figsize=(12, 8))\n",
    "    # plt.plot(prediction, label='rf')\n",
    "    # plt.plot(y, label='y')\n",
    "    # plt.xlabel(y.index)\n",
    "    # plt.legend()\n",
    "    # plt.show()\n",
    "    with open('meteorological/model/rf/selected_features_rfecv_model.pkl', 'wb') as file:\n",
    "        pickle.dump(rfecv, file)\n",
    "    return rfecv"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "help(RFECV)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rfecv = rfecv_run_model(TES_X_train, TES_X_test,y_train, y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "selected_features = TES_X_test.columns[rfecv.support_]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (accuracy)\")\n",
    "plt.plot(\n",
    "    range(rfecv.min_features_to_select, len(rfecv.grid_scores_) + rfecv.min_features_to_select),\n",
    "    rfecv.grid_scores_,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['이슬점온도', '기온', '상대습도', '강수량', '일조량', '지면온도', '풍속', '기압', '시정(가시거리)',\n       'TESadd_add25이슬점온도', 'TESadd_add68이슬점온도', 'TESadd_add156이슬점온도',\n       'TESadd_add288이슬점온도', 'TESadd_add576이슬점온도', 'TESadd_add25기온',\n       'TESadd_add68기온', 'TESadd_add156기온', 'TESadd_add288기온',\n       'TESadd_add576기온', 'TESadd_add25상대습도', 'TESadd_add68상대습도',\n       'TESadd_add156상대습도', 'TESadd_add288상대습도', 'TESadd_add576상대습도',\n       'TESadd_add25강수량', 'TESadd_add68강수량', 'TESadd_add156강수량',\n       'TESadd_add576강수량', 'TESadd_add25일조량', 'TESadd_add68일조량',\n       'TESadd_add156일조량', 'TESadd_add288일조량', 'TESadd_add576일조량',\n       'TESadd_add25지면온도', 'TESadd_add68지면온도', 'TESadd_add156지면온도',\n       'TESadd_add288지면온도', 'TESadd_add576지면온도', 'TESadd_add25풍속',\n       'TESadd_add68풍속', 'TESadd_add156풍속', 'TESadd_add288풍속',\n       'TESadd_add576풍속', 'TESadd_add25기압', 'TESadd_add68기압',\n       'TESadd_add156기압', 'TESadd_add288기압', 'TESadd_add576기압',\n       'TESadd_add25시정(가시거리)', 'TESadd_add68시정(가시거리)', 'TESadd_add156시정(가시거리)',\n       'TESadd_add288시정(가시거리)', 'TESadd_add576시정(가시거리)'],\n      dtype='object')"
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
